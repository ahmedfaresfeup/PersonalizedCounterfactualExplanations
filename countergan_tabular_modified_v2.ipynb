{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz5mmOdOHznl"
      },
      "source": [
        "# Counterfactuals benchmark on tabular datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYNbfZ4CbwI_",
        "outputId": "a152bcac-e593-4f83-e9b5-ffb9412f9cf9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-17 09:57:35.928239: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-06-17 09:57:35.967922: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-06-17 09:57:35.967956: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-06-17 09:57:35.967986: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-17 09:57:35.976027: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-06-17 09:57:36.609645: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current working directory: /home/ahmed/prototype\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "# tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "\n",
        "BASE_PATH = \"./counterfactuals\"\n",
        "print(\"Current working directory:\", os.getcwd())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7sVjpCaH3yD"
      },
      "source": [
        "## Imports and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tW1SdKmbrbj",
        "outputId": "eb57f82e-de9d-4046-de2d-e154bdea3863"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ahmed/prototype/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alibi version: 0.9.7.dev0\n",
            "Is TensorFlow running in eager execution mode? -----→ False\n",
            "GPU 0: NVIDIA GeForce RTX 4060 Laptop GPU (UUID: GPU-ed7340f2-1910-df12-4a83-29feeba52695)\n"
          ]
        }
      ],
      "source": [
        "# Install the dev version of the Alibi package if not already installed\n",
        "try:\n",
        "    from alibi import __version__ as alibi_version\n",
        "    print(f\"Alibi version: {alibi_version}\")\n",
        "except ImportError:\n",
        "    print(\"Alibi package not found, installing...\")\n",
        "    # Install the dev version of Alibi\n",
        "    !pip install git+https://github.com/SeldonIO/alibi.git > /dev/null\n",
        "\n",
        "\n",
        "import logging\n",
        "\n",
        "alibi_logger = logging.getLogger(\"alibi\")\n",
        "alibi_logger.setLevel(\"CRITICAL\")\n",
        "\n",
        "\n",
        "print(f\"Is TensorFlow running in eager execution mode? -----→ {tf.executing_eagerly()}\")\n",
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6aJpXl3siWZr"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "if not os.path.exists(BASE_PATH):\n",
        "    os.makedirs(BASE_PATH)\n",
        "\n",
        "\n",
        "date = datetime.now().strftime('%Y-%m-%d')\n",
        "EXPERIMENT_PATH = f\"{BASE_PATH}/diabetes_{date}\"\n",
        "MODELS_EXPERIMENT_PATH = f\"{BASE_PATH}/diabetes_2020-09-09\"\n",
        "if not os.path.exists(EXPERIMENT_PATH):\n",
        "    os.makedirs(EXPERIMENT_PATH)\n",
        "    \n",
        "# os.chdir(BASE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07Ne3HvYI8dv"
      },
      "source": [
        "## Data import and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "mAPAZpVUiks-",
        "outputId": "f7628cfa-2bd6-4c90-e027-d90f0ecf58b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current working directory: /home/ahmed/prototype\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Insulin",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Glucose",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "SkinThickness",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "BMI",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "BloodPressure",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Age",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "DiabetesPedigreeFunction",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Pregnancies",
                  "rawType": "int64",
                  "type": "integer"
                }
              ],
              "ref": "951ff1a2-069f-4b5e-89ba-fe612e2e3a43",
              "rows": [
                [
                  "379",
                  "72",
                  "93",
                  "39",
                  "43.4",
                  "100",
                  "35",
                  "1.021",
                  "0"
                ],
                [
                  "741",
                  "94",
                  "102",
                  "20",
                  "30.8",
                  "44",
                  "26",
                  "0.4",
                  "3"
                ],
                [
                  "102",
                  "0",
                  "125",
                  "0",
                  "22.5",
                  "96",
                  "21",
                  "0.262",
                  "0"
                ],
                [
                  "641",
                  "0",
                  "128",
                  "0",
                  "34.3",
                  "70",
                  "24",
                  "0.303",
                  "4"
                ],
                [
                  "14",
                  "175",
                  "166",
                  "19",
                  "25.8",
                  "72",
                  "51",
                  "0.587",
                  "5"
                ]
              ],
              "shape": {
                "columns": 8,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Insulin</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>BMI</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>Age</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Pregnancies</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>379</th>\n",
              "      <td>72</td>\n",
              "      <td>93</td>\n",
              "      <td>39</td>\n",
              "      <td>43.4</td>\n",
              "      <td>100</td>\n",
              "      <td>35</td>\n",
              "      <td>1.021</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>741</th>\n",
              "      <td>94</td>\n",
              "      <td>102</td>\n",
              "      <td>20</td>\n",
              "      <td>30.8</td>\n",
              "      <td>44</td>\n",
              "      <td>26</td>\n",
              "      <td>0.400</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>0</td>\n",
              "      <td>125</td>\n",
              "      <td>0</td>\n",
              "      <td>22.5</td>\n",
              "      <td>96</td>\n",
              "      <td>21</td>\n",
              "      <td>0.262</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>641</th>\n",
              "      <td>0</td>\n",
              "      <td>128</td>\n",
              "      <td>0</td>\n",
              "      <td>34.3</td>\n",
              "      <td>70</td>\n",
              "      <td>24</td>\n",
              "      <td>0.303</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>175</td>\n",
              "      <td>166</td>\n",
              "      <td>19</td>\n",
              "      <td>25.8</td>\n",
              "      <td>72</td>\n",
              "      <td>51</td>\n",
              "      <td>0.587</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Insulin  Glucose  SkinThickness   BMI  BloodPressure  Age  \\\n",
              "379       72       93             39  43.4            100   35   \n",
              "741       94      102             20  30.8             44   26   \n",
              "102        0      125              0  22.5             96   21   \n",
              "641        0      128              0  34.3             70   24   \n",
              "14       175      166             19  25.8             72   51   \n",
              "\n",
              "     DiabetesPedigreeFunction  Pregnancies  \n",
              "379                     1.021            0  \n",
              "741                     0.400            3  \n",
              "102                     0.262            0  \n",
              "641                     0.303            4  \n",
              "14                      0.587            5  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "import pickle\n",
        "import time\n",
        "from matplotlib import offsetbox\n",
        "from matplotlib.colors import ListedColormap\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from tensorflow.keras.layers import Dense, Add, Input, ActivityRegularization, Concatenate, Multiply\n",
        "from tensorflow.keras import optimizers, Model, regularizers, Input\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Add, Input, ActivityRegularization\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "\n",
        "print(\"Current working directory:\", os.getcwd())\n",
        "\n",
        "INITIAL_CLASS = 0\n",
        "DESIRED_CLASS = 1\n",
        "N_CLASSES = 2\n",
        "n_training_iterations = 10\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "tf.random.set_seed(2020)\n",
        "np.random.seed(2020)\n",
        "\n",
        "# Pima indians Diabetes dataset\n",
        "# https://www.kaggle.com/uciml/pima-indians-diabetes-database\n",
        "df = pd.read_csv(\"diabetes.csv\", index_col=False)\n",
        "target_column = \"Outcome\"\n",
        "immutable_features = {\"Pregnancies\", \"DiabetesPedigreeFunction\", \"Age\"}\n",
        "\n",
        "features = set(df.columns) - {target_column}\n",
        "mutable_features = features - immutable_features\n",
        "features = list(mutable_features) + list(immutable_features)\n",
        "\n",
        "x = df[features]\n",
        "y = df[target_column].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[features].values, y, test_size=0.2)\n",
        "\n",
        "standard_scaler = StandardScaler()\n",
        "X_train = standard_scaler.fit_transform(X_train)\n",
        "X_test = standard_scaler.transform(X_test)\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "df[features].sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vTcm3LgfKEtl"
      },
      "outputs": [],
      "source": [
        "def compute_reconstruction_error(x, autoencoder):\n",
        "    \"\"\"Compute the reconstruction error for a given autoencoder and data points.\"\"\"\n",
        "    preds = autoencoder.predict(x)\n",
        "    preds_flat = preds.reshape((preds.shape[0], -1))\n",
        "    x_flat = x.reshape((x.shape[0], -1))\n",
        "    return np.linalg.norm(x_flat - preds_flat, axis=1)\n",
        "\n",
        "def format_metric(metric):\n",
        "    \"\"\"Return a formatted version of a metric, with the confidence interval.\"\"\"\n",
        "    return f\"{metric.mean():.3f} ± {1.96*metric.std()/np.sqrt(len(metric)):.3f}\"\n",
        "\n",
        "def compute_metrics(samples, counterfactuals, latencies, classifier, autoencoder,\n",
        "                    batch_latency=None):\n",
        "    \"\"\" Summarize the relevant metrics in a dictionary. \"\"\"\n",
        "    reconstruction_error = compute_reconstruction_error(counterfactuals, autoencoder)\n",
        "    delta = np.abs(samples-counterfactuals)\n",
        "    l1_distances = delta.reshape(delta.shape[0], -1).sum(axis=1)\n",
        "    prediction_gain = (\n",
        "        classifier.predict(counterfactuals)[:, DESIRED_CLASS] - \n",
        "        classifier.predict(samples)[:, DESIRED_CLASS]\n",
        "    )\n",
        "\n",
        "    metrics = dict()\n",
        "    metrics[\"reconstruction_error\"] = format_metric(reconstruction_error)\n",
        "    metrics[\"prediction_gain\"] = format_metric(prediction_gain)\n",
        "    metrics[\"sparsity\"] = format_metric(l1_distances)\n",
        "    metrics[\"latency\"] = format_metric(latencies)\n",
        "    batch_latency = batch_latency if batch_latency else sum(latencies)\n",
        "    metrics[\"latency_batch\"] = f\"{batch_latency:.3f}\"\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def save_experiment(method_name, samples, counterfactuals, latencies, \n",
        "                    batch_latency=None):\n",
        "    \"\"\"Create an experiment folder and save counterfactuals, latencies and metrics.\"\"\"\n",
        "    if not os.path.exists(f\"{EXPERIMENT_PATH}/{method_name}\"):\n",
        "        os.makedirs(f\"{EXPERIMENT_PATH}/{method_name}\")   \n",
        "\n",
        "    np.save(f\"{EXPERIMENT_PATH}/{method_name}/counterfactuals.npy\", counterfactuals)\n",
        "    np.save(f\"{EXPERIMENT_PATH}/{method_name}/latencies.npy\", latencies)\n",
        "\n",
        "    metrics = compute_metrics(samples, counterfactuals, latencies, classifier, autoencoder)\n",
        "    json.dump(metrics, open(f\"{EXPERIMENT_PATH}/{method_name}/metrics.json\", \"w\"))\n",
        "    pprint(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmw26uWLiw2c",
        "outputId": "b89cf614-ecd1-4638-9c6e-0c91a4d81f1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "Classifier loaded from ./counterfactuals/diabetes_2025-06-17/classifier.keras\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Add, Input, ActivityRegularization\n",
        "from tensorflow.keras import Model, optimizers, regularizers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "tf.random.set_seed(2020)\n",
        "np.random.seed(2020)\n",
        "\n",
        "# def create_classifier(input_shape):\n",
        "#     \"\"\"Define and compile a neural network binary classifier.\"\"\" \n",
        "#     model = Sequential([\n",
        "#         Dense(20, activation='relu', input_shape=input_shape),\n",
        "#         Dense(20, activation='relu'),\n",
        "#         Dense(2, activation='softmax'),\n",
        "#     ], name=\"classifier\")\n",
        "#     optimizer = optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "#     model.compile(optimizer, 'binary_crossentropy', ['accuracy'])\n",
        "#     return model\n",
        "\n",
        "# classifier = create_classifier((x.shape[1],))\n",
        "# print(X_train.dtype, y_train.dtype)\n",
        "# print(X_test.dtype, y_test.dtype)\n",
        "\n",
        "# X_train = X_train.astype(np.float32)\n",
        "# X_test = X_test.astype(np.float32)\n",
        "# y_train = y_train.astype(np.float32)\n",
        "# y_test = y_test.astype(np.float32)\n",
        "# training = classifier.fit(X_train, y_train, batch_size=32, epochs=200, verbose=0,\n",
        "#                           validation_data=(X_test, y_test),)\n",
        "# print(f\"Training: loss={training.history['loss'][-1]:.4f}, \"\n",
        "#       f\"accuracy={training.history['accuracy'][-1]:.4f}\")\n",
        "# print(f\"Validation: loss={training.history['val_loss'][-1]:.4f}, \"\n",
        "#       f\"accuracy={training.history['val_accuracy'][-1]:.4f}\")\n",
        "\n",
        "# classifier.save(f\"{EXPERIMENT_PATH}/classifier.keras\")\n",
        "\n",
        "# Load the classifier model\n",
        "filename = f\"{EXPERIMENT_PATH}/classifier.keras\"\n",
        "classifier = load_model(filename)\n",
        "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "print(f\"Classifier loaded from {filename}\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gY6FCuwuZ75"
      },
      "source": [
        "## Estimate density with the reconstruction error of a (denoising) autoencoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHvMh2YG3hRK",
        "outputId": "f44437fa-8c44-43c9-8b90-088cfeb07938"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "Autoencoder loaded from ./counterfactuals/diabetes_2025-06-17/autoencoder.keras\n"
          ]
        }
      ],
      "source": [
        "# def add_noise(x, noise_factor=1e-6):\n",
        "#     x_noisy = x + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x.shape) \n",
        "#     return x_noisy\n",
        "\n",
        "    \n",
        "# def create_autoencoder(in_shape=(x.shape[1],)):\n",
        "#     input_ = Input(shape=in_shape) \n",
        "\n",
        "#     x = Dense(32, activation=\"relu\")(input_)\n",
        "#     encoded = Dense(8)(x)\n",
        "#     x = Dense(32, activation=\"relu\")(encoded)\n",
        "#     decoded = Dense(in_shape[0], activation=\"tanh\")(x)\n",
        "\n",
        "#     autoencoder = Model(input_, decoded)\n",
        "#     optimizer = optimizers.Nadam()\n",
        "#     autoencoder.compile(optimizer, 'mse')\n",
        "#     return autoencoder\n",
        "\n",
        "# autoencoder = create_autoencoder()\n",
        "# training = autoencoder.fit(\n",
        "#     add_noise(X_train), X_train, epochs=100, batch_size=32, shuffle=True, \n",
        "#     validation_data=(X_test, X_test), verbose=0\n",
        "# )\n",
        "# print(f\"Training loss: {training.history['loss'][-1]:.4f}\")\n",
        "# print(f\"Validation loss: {training.history['val_loss'][-1]:.4f}\")\n",
        "\n",
        "# n_samples = 1000\n",
        "# # Compute the reconstruction error of noise data\n",
        "# samples = np.random.randn(n_samples, X_train.shape[1])\n",
        "# reconstruction_error_noise = compute_reconstruction_error(samples, autoencoder)\n",
        "\n",
        "# # Save and print the autoencoder metrics\n",
        "# reconstruction_error = compute_reconstruction_error(X_test, autoencoder)\n",
        "# autoencoder_metrics = {\n",
        "#     \"reconstruction_error\": format_metric(reconstruction_error),\n",
        "#     \"reconstruction_error_noise\": format_metric(reconstruction_error_noise),\n",
        "# }\n",
        "# json.dump(autoencoder_metrics, open(f\"{EXPERIMENT_PATH}/autoencoder_metrics.json\", \"w\"))\n",
        "# pprint(autoencoder_metrics)\n",
        "\n",
        "# autoencoder.save(f\"{EXPERIMENT_PATH}/autoencoder.keras\")\n",
        "\n",
        "# Load the autoencoder model\n",
        "filename = f\"{EXPERIMENT_PATH}/autoencoder.keras\" \n",
        "autoencoder = load_model(filename)\n",
        "# Ensure the autoencoder is compiled with the same optimizer and loss function  \n",
        "autoencoder.compile(optimizer='nadam', loss='mse')\n",
        "\n",
        "print(f\"Autoencoder loaded from {filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JcccJKG87kU"
      },
      "source": [
        "## Regularized Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dA5sU3Pf1k5",
        "outputId": "d973d943-cddd-43ef-dcd1-e27ac2ea412a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ahmed/prototype/.venv/lib/python3.9/site-packages/alibi/explainers/counterfactual.py:71: FutureWarning: The class name `CounterFactual` is deprecated, please use `Counterfactual`.\n",
            "  warnings.warn(warning_msg, FutureWarning)\n",
            "2025-06-17 09:57:39.395600: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-06-17 09:57:39.440446: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-06-17 09:57:39.440495: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-06-17 09:57:39.443552: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-06-17 09:57:39.443623: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-06-17 09:57:39.443657: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-06-17 09:57:39.610149: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-06-17 09:57:39.610253: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-06-17 09:57:39.610265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
            "2025-06-17 09:57:39.610309: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-06-17 09:57:39.610354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
            "2025-06-17 09:57:39.618221: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n",
            "2025-06-17 09:57:39.818774: W tensorflow/c/c_api.cc:305] Operation '{name:'dense_6/bias/Assign' id:239 op device:{requested: '', assigned: ''} def:{{{node dense_6/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_6/bias, dense_6/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
            "/home/ahmed/prototype/.venv/lib/python3.9/site-packages/keras/src/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n",
            "2025-06-17 09:57:40.373841: W tensorflow/c/c_api.cc:305] Operation '{name:'dense_2/Softmax' id:74 op device:{requested: '', assigned: ''} def:{{{node dense_2/Softmax}} = Softmax[T=DT_FLOAT, _has_manual_control_dependencies=true](dense_2/BiasAdd)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Produced explanation in 2.20 seconds \n",
            "Original prediction: 1 with probability 0.773\n",
            "Counterfactual prediction: 1 with probability 0.795\n",
            "Suggested perturbations: [-0.1 -0.1 -0.1  0.1  0.1  0.   0.   0. ]\n"
          ]
        }
      ],
      "source": [
        "from alibi.explainers import CounterFactual\n",
        "\n",
        "shape = (1,) + X_train.shape[1:]\n",
        "feature_range = (X_train.min(), X_train.max())\n",
        "\n",
        "cf = CounterFactual(classifier, shape=shape, target_proba=1.0, tol=0.5,\n",
        "                    target_class=DESIRED_CLASS, max_iter=100, lam_init=0.001,\n",
        "                    max_lam_steps=5, learning_rate_init=0.1,\n",
        "                    feature_range=feature_range)\n",
        "\n",
        "sample = X_test[4]\n",
        "\n",
        "t_initial = time.time()\n",
        "explanation = cf.explain(np.expand_dims(sample, axis=0))\n",
        "print(f\"Produced explanation in {time.time() - t_initial:.2f} seconds \")\n",
        "\n",
        "y_prob = classifier.predict(np.expand_dims(sample, axis=0))[0]\n",
        "print(f'Original prediction: {y_prob.argmax()} with probability {y_prob.max():.3f}')\n",
        "\n",
        "pred_class = explanation.cf['class']\n",
        "proba = explanation.cf['proba'][0][pred_class]\n",
        "print(f'Counterfactual prediction: {pred_class} with probability {proba:.3f}')\n",
        "\n",
        "perturbations = (explanation.cf['X'] - sample)[0]\n",
        "perturbations[-len(immutable_features):] = 0.\n",
        "print(f\"Suggested perturbations: {perturbations}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "EXJ-JYqBGmxC",
        "outputId": "fec2b652-7a53-4b72-f3b9-e482e58f7888"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 0 at 2025-06-17 09:57:42.753806\n",
            "Iteration 20 at 2025-06-17 09:58:18.764922\n",
            "Iteration 40 at 2025-06-17 09:58:54.181641\n",
            "Iteration 60 at 2025-06-17 09:59:29.577561\n",
            "Iteration 80 at 2025-06-17 10:00:04.852896\n",
            "Iteration 100 at 2025-06-17 10:00:40.179499\n",
            "Iteration 120 at 2025-06-17 10:01:15.400429\n",
            "Iteration 140 at 2025-06-17 10:01:50.448258\n",
            "Iteration 153 at 2025-06-17 10:02:13.661497\n",
            "Metrics before immutable features projection:\n",
            "{'latency': '1770.123 ± 30.214',\n",
            " 'latency_batch': '272598.989',\n",
            " 'prediction_gain': '0.034 ± 0.003',\n",
            " 'reconstruction_error': '2.839 ± 0.169',\n",
            " 'sparsity': '0.902 ± 0.064'}\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics after immutable features projection:\n",
            "{'latency': '1770.123 ± 30.214',\n",
            " 'latency_batch': '272598.989',\n",
            " 'prediction_gain': '0.021 ± 0.002',\n",
            " 'reconstruction_error': '2.817 ± 0.168',\n",
            " 'sparsity': '0.567 ± 0.042'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-17 10:02:15.355616: W tensorflow/c/c_api.cc:305] Operation '{name:'dense_6/Tanh' id:245 op device:{requested: '', assigned: ''} def:{{{node dense_6/Tanh}} = Tanh[T=DT_FLOAT, _has_manual_control_dependencies=true](dense_6/BiasAdd)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
          ]
        }
      ],
      "source": [
        "samples = X_test \n",
        "\n",
        "latencies = np.empty(len(samples))\n",
        "counterfactuals = np.empty_like(samples)\n",
        "\n",
        "for i, sample in enumerate(samples):\n",
        "    if ((i % 20) == 0) or (i == (len(samples)-1)):\n",
        "        print(f\"Iteration {i} at {datetime.now()}\")\n",
        "    t_initial = time.time()\n",
        "    try:\n",
        "        explanation = cf.explain(np.expand_dims(sample, axis=0))\n",
        "        counterfactuals[i] = explanation.cf['X']\n",
        "    except (UnboundLocalError, TypeError):  # counterfactual search failed\n",
        "        print(f\"{i}-th sampled failed\")\n",
        "        counterfactuals[i] = sample\n",
        "    latencies[i] = 1000*(time.time() - t_initial)\n",
        "\n",
        "print(\"Metrics before immutable features projection:\")\n",
        "pprint(compute_metrics(samples, counterfactuals, latencies, classifier, autoencoder,\n",
        "                    batch_latency=None))\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Set immutable features to original values\n",
        "counterfactuals[:, len(mutable_features):] = samples[:, len(mutable_features):]\n",
        "\n",
        "print(\"Metrics after immutable features projection:\")\n",
        "save_experiment(\"rgd\", samples, counterfactuals, latencies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWMMH-btKLOB"
      },
      "source": [
        "## Counterfactual Search Guided by Prototypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2YxnNtLuKOHA"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ahmed/prototype/.venv/lib/python3.9/site-packages/alibi/explainers/cfproto.py:29: FutureWarning: The class name `CounterFactualProto` is deprecated, please use `CounterfactualProto`.\n",
            "  warnings.warn(warning_msg, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "from alibi.explainers import CounterFactualProto\n",
        "\n",
        "shape = (1,) + X_train.shape[1:]\n",
        "feature_range = (X_train.min(), X_train.max())\n",
        "\n",
        "cf_proto = CounterFactualProto(\n",
        "    classifier, shape, use_kdtree=True, theta=10., feature_range=feature_range,\n",
        "    max_iterations=200, c_steps=10\n",
        ")\n",
        "cf_proto.fit(X_train, trustscore_kwargs=None);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2o4wfCfsKcge",
        "outputId": "0805439a-2a64-47b5-9e8c-97698abea977"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Produced explanation in 9.50 seconds \n",
            "Original prediction: 1 with probability 0.773\n",
            "No counterfactual found for this sample.\n"
          ]
        }
      ],
      "source": [
        "sample = X_test[4]\n",
        "\n",
        "t_initial = time.time()\n",
        "explanation = cf_proto.explain(\n",
        "    np.expand_dims(sample, axis=0), k=5, k_type='mean', target_class=[DESIRED_CLASS]\n",
        ")\n",
        "\n",
        "print(f\"Produced explanation in {time.time() - t_initial:.2f} seconds \")\n",
        "\n",
        "y_prob = classifier.predict(np.expand_dims(sample, axis=0))[0]\n",
        "print(f'Original prediction: {y_prob.argmax()} with probability {y_prob.max():.3f}')\n",
        "\n",
        "if explanation.cf is not None:\n",
        "    pred_class = explanation.cf['class']\n",
        "    proba = explanation.cf['proba'][0][pred_class]\n",
        "    print(f'Counterfactual prediction: {pred_class} with probability {proba:.3f}')\n",
        "    perturbations = (explanation.cf['X'] - sample)[0]\n",
        "    perturbations[-len(immutable_features):] = 0.\n",
        "    print(f\"Suggested perturbations: {perturbations}\")\n",
        "else:\n",
        "    print(\"No counterfactual found for this sample.\")\n",
        "    counterfactual = sample  # fallback to original sample\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "62zJUpDjKin9",
        "outputId": "6d825fb6-e247-47da-dfe0-3f3cd54caa82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1-th iteration at 2025-06-17 10:02:25.033405\n",
            "21-th iteration at 2025-06-17 10:05:20.552713\n",
            "41-th iteration at 2025-06-17 10:08:17.423466\n",
            "61-th iteration at 2025-06-17 10:11:12.870743\n",
            "81-th iteration at 2025-06-17 10:14:06.020887\n",
            "101-th iteration at 2025-06-17 10:17:01.754115\n",
            "121-th iteration at 2025-06-17 10:19:54.989221\n",
            "141-th iteration at 2025-06-17 10:22:48.380045\n",
            "154-th iteration at 2025-06-17 10:24:42.698936\n",
            "Metrics before immutable features projection:\n",
            "{'latency': '8741.106 ± 76.150',\n",
            " 'latency_batch': '1346130.346',\n",
            " 'prediction_gain': '0.008 ± 0.004',\n",
            " 'reconstruction_error': '2.731 ± 0.167',\n",
            " 'sparsity': '0.136 ± 0.061'}\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics after immutable features projection:\n",
            "{'latency': '8741.106 ± 76.150',\n",
            " 'latency_batch': '1346130.346',\n",
            " 'prediction_gain': '0.005 ± 0.003',\n",
            " 'reconstruction_error': '2.738 ± 0.166',\n",
            " 'sparsity': '0.092 ± 0.046'}\n"
          ]
        }
      ],
      "source": [
        "verbose = False\n",
        "samples = X_test\n",
        "\n",
        "latencies = np.empty(len(samples))\n",
        "counterfactuals = np.empty_like(samples)\n",
        "for i, sample in enumerate(samples):\n",
        "    if ((i % 20) == 0) or (i == (len(samples)-1)):\n",
        "        print(f\"{i+1}-th iteration at {datetime.now()}\")\n",
        "    t_initial = time.time()\n",
        "    try:\n",
        "        explanation = cf_proto.explain(np.expand_dims(sample, axis=0), k=20, \n",
        "                                       k_type='mean', target_class=[DESIRED_CLASS])\n",
        "        counterfactuals[i] = explanation.cf['X']\n",
        "    except (UnboundLocalError, TypeError) as e:  # counterfactual search failed\n",
        "        if verbose:\n",
        "            print(f\"{i}-th sampled failed\")\n",
        "        counterfactuals[i] = sample\n",
        "    latencies[i] = 1000*(time.time() - t_initial)\n",
        "\n",
        "print(\"Metrics before immutable features projection:\")\n",
        "pprint(compute_metrics(samples, counterfactuals, latencies, classifier, autoencoder,\n",
        "                    batch_latency=None))\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Set immutable features to original values\n",
        "counterfactuals[:, len(mutable_features):] = samples[:, len(mutable_features):]\n",
        "\n",
        "print(\"Metrics after immutable features projection:\")\n",
        "save_experiment(\"csgp\", samples, counterfactuals, latencies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwoisov75MsD"
      },
      "source": [
        "## GAN-based counterfactual search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Gi9faGZ42qRR"
      },
      "outputs": [],
      "source": [
        "def generate_fake_samples(x, generator):\n",
        "    \"\"\"Use the input generator to generate samples.\"\"\"\n",
        "    return generator.predict(x)\n",
        "\n",
        "def data_stream(x, y=None, batch_size=500):\n",
        "    \"\"\"Generate batches until exhaustion of the input data.\"\"\"\n",
        "    n_train = x.shape[0]\n",
        "    if y is not None:\n",
        "        assert n_train == len(y)\n",
        "    n_complete_batches, leftover = divmod(n_train, batch_size)\n",
        "    n_batches = n_complete_batches + bool(leftover)\n",
        "\n",
        "    perm = np.random.permutation(n_train)\n",
        "    for i in range(n_batches):\n",
        "        batch_idx = perm[i * batch_size:(i + 1) * batch_size]\n",
        "        if y is not None:\n",
        "            output = (x[batch_idx], y[batch_idx])\n",
        "        else:\n",
        "            output = x[batch_idx]\n",
        "        yield output\n",
        "\n",
        "\n",
        "def infinite_data_stream(x, y=None, batch_size=500):\n",
        "    \"\"\"Infinite batch generator.\"\"\"\n",
        "    batches = data_stream(x, y, batch_size=batch_size)\n",
        "    while True:\n",
        "        try:\n",
        "            yield next(batches)\n",
        "        except StopIteration:\n",
        "            batches = data_stream(x, y, batch_size=batch_size)\n",
        "            yield next(batches)\n",
        "\n",
        "def create_generator(in_shape=(X_train.shape[1],), residuals=True):\n",
        "    \"\"\"Define and compile the residual generator of the CounteRGAN.\"\"\"\n",
        "    generator_input = Input(shape=in_shape, name='generator_input')\n",
        "    generator = Dense(64, activation='relu')(generator_input)\n",
        "    generator = Dense(32, activation='relu')(generator)\n",
        "    generator = Dense(64, activation='relu')(generator)\n",
        "    generator = Dense(in_shape[0], activation='tanh')(generator)\n",
        "    generator_output = ActivityRegularization(l1=0., l2=1e-6)(generator)\n",
        "    \n",
        "    if residuals:\n",
        "        generator_output = Add(name=\"output\")([generator_input, generator_output])\n",
        "\n",
        "    return Model(inputs=generator_input, outputs=generator_output)\n",
        "\n",
        "\n",
        "def create_discriminator(in_shape=(X_train.shape[1],)):\n",
        "    \"\"\" Define a neural network binary classifier to classify real and generated \n",
        "    examples.\"\"\"\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=in_shape),\n",
        "        Dropout(0.2),\n",
        "        Dense(1, activation='sigmoid'),\n",
        "    ], name=\"discriminator\")\n",
        "    optimizer = optimizers.legacy.Adam(learning_rate=0.0005, beta_1=0.5, decay=1e-8)\n",
        "    model.compile(optimizer, 'binary_crossentropy', ['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def define_countergan(generator, discriminator, classifier, \n",
        "                      input_shape=(X_train.shape[1],)):\n",
        "    \"\"\"Combine a generator, discriminator, and fixed classifier into the CounteRGAN.\"\"\"\n",
        "    discriminator.trainable = False\n",
        "    classifier.trainable = False\n",
        "\n",
        "    countergan_input = Input(shape=input_shape, name='countergan_input')\n",
        "  \n",
        "    x_generated = generator(countergan_input)\n",
        "\n",
        "    countergan = Model(\n",
        "        inputs=countergan_input, \n",
        "        outputs=[discriminator(x_generated), classifier(x_generated)]\n",
        "    )\n",
        "        \n",
        "    optimizer = optimizers.legacy.RMSprop(learning_rate=2e-4, decay=1e-8)\n",
        "    countergan.compile(optimizer, [\"binary_crossentropy\", \"categorical_crossentropy\"])\n",
        "    return countergan\n",
        "\n",
        "\n",
        "def define_weighted_countergan(generator, discriminator, \n",
        "                               input_shape=(X_train.shape[1],)):\n",
        "    \"\"\"Combine a generator and a discriminator for the weighted version of the \n",
        "    CounteRGAN.\"\"\"\n",
        "    discriminator.trainable = False\n",
        "    classifier.trainable = False\n",
        "    countergan_input = Input(shape=input_shape, name='countergan_input')\n",
        "  \n",
        "    x_generated = generator(countergan_input)\n",
        "\n",
        "    countergan = Model(inputs=countergan_input, outputs=discriminator(x_generated))\n",
        "    optimizer = optimizers.legacy.RMSprop(learning_rate=5e-4, decay=1e-8)\n",
        "    countergan.compile(optimizer, \"binary_crossentropy\")  \n",
        "    return countergan\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ufnw6FKdPpa2"
      },
      "outputs": [],
      "source": [
        "def train_countergan(n_discriminator_steps, n_generator_steps, n_training_iterations,\n",
        "                     classifier, discriminator, generator, batches, \n",
        "                     weighted_version=False):\n",
        "    \"\"\" Main function: train the CounteRGAN\"\"\"\n",
        "    def check_divergence(x_generated):\n",
        "        return np.all(np.isnan(x_generated))\n",
        "\n",
        "    def print_training_information(generator, classifier, X_test, iteration):\n",
        "        X_gen = generator.predict(X_test)\n",
        "        clf_pred_test = classifier.predict(X_test)\n",
        "        clf_pred = classifier.predict(X_gen)\n",
        "\n",
        "        delta_clf_pred = (clf_pred - clf_pred_test)[:, DESIRED_CLASS]\n",
        "        y_target = to_categorical([DESIRED_CLASS] * len(clf_pred), \n",
        "                                  num_classes=N_CLASSES)\n",
        "        print('='*88)\n",
        "        print(f\"Training iteration {iteration} at {datetime.now()}\")\n",
        "        \n",
        "        \n",
        "        reconstruction_error = np.mean(compute_reconstruction_error(X_gen, autoencoder))\n",
        "        print(f\"Autoencoder reconstruction error (infinity to 0): {reconstruction_error:.3f}\")\n",
        "        print(f\"Counterfactual prediction gain (0 to 1): {delta_clf_pred.mean():.3f}\")\n",
        "        print(f\"Sparsity (L1, infinity to 0): {np.mean(np.abs(X_gen-X_test)):.3f}\")\n",
        "\n",
        "    if weighted_version:\n",
        "        countergan = define_weighted_countergan(generator, discriminator)\n",
        "    else:\n",
        "        countergan = define_countergan(generator, discriminator, classifier)\n",
        "\n",
        "    for iteration in range(n_training_iterations):\n",
        "        if iteration > 0:\n",
        "            x_generated = generator.predict(x_fake_input)\n",
        "            if check_divergence(x_generated):\n",
        "                print(\"Training diverged with the following loss functions:\")\n",
        "                print(discrim_loss_1, discrim_accuracy, gan_loss, \n",
        "                    discrim_loss, discrim_loss_2, clf_loss)\n",
        "                break\n",
        "\n",
        "        # Periodically print and plot training information \n",
        "        if (iteration % 1000 == 0) or (iteration == n_training_iterations - 1):\n",
        "            print_training_information(generator, classifier, X_test, iteration)\n",
        "\n",
        "        # Train the discriminator\n",
        "        discriminator.trainable = True\n",
        "        for _ in range(n_discriminator_steps):\n",
        "            x_fake_input, _ = next(batches)\n",
        "            x_fake = generate_fake_samples(x_fake_input, generator)\n",
        "            x_real = x_fake_input\n",
        "\n",
        "            x_batch = np.concatenate([x_real, x_fake])\n",
        "            y_batch = np.concatenate([np.ones(len(x_real)), np.zeros(len(x_fake))])\n",
        "            \n",
        "            # Shuffle real and fake examples\n",
        "            p = np.random.permutation(len(y_batch))\n",
        "            x_batch, y_batch = x_batch[p], y_batch[p]\n",
        "\n",
        "            if weighted_version:\n",
        "                classifier_scores = classifier.predict(x_batch)[:, DESIRED_CLASS]\n",
        "                \n",
        "                # The following update to the classifier scores is needed to have the \n",
        "                # same order of magnitude between real and generated samples losses\n",
        "                real_samples = np.where(y_batch == 1.)\n",
        "                average_score_real_samples = np.mean(classifier_scores[real_samples])\n",
        "                classifier_scores[real_samples] /= average_score_real_samples\n",
        "                \n",
        "                fake_samples = np.where(y_batch == 0.)\n",
        "                classifier_scores[fake_samples] = 1.\n",
        "\n",
        "                discriminator.train_on_batch(\n",
        "                    x_batch, y_batch, sample_weight=classifier_scores\n",
        "                )\n",
        "            else:\n",
        "                discriminator.train_on_batch(x_batch, y_batch)\n",
        "\n",
        "        # Train the generator \n",
        "        discriminator.trainable = False\n",
        "        for _ in range(n_generator_steps):\n",
        "            x_fake_input, _ = next(batches)\n",
        "            y_fake = np.ones(len(x_fake_input))\n",
        "            if weighted_version:\n",
        "                countergan.train_on_batch(x_fake_input, y_fake)\n",
        "            else:\n",
        "                y_target = to_categorical([DESIRED_CLASS] * len(x_fake_input), \n",
        "                                          num_classes=N_CLASSES)\n",
        "                countergan.train_on_batch(x_fake_input, [y_fake, y_target])\n",
        "    return countergan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpaZptCP2k_U"
      },
      "source": [
        "## Counterfactual search with a regular GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "L4PL01njRnV9",
        "outputId": "dbaea06d-6f95-4bf7-c02e-15daaeed5164"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-17 10:24:51.257109: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-06-17 10:24:51.257231: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-06-17 10:24:51.257309: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-06-17 10:24:51.257570: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-06-17 10:24:51.257585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
            "2025-06-17 10:24:51.257623: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-06-17 10:24:51.257641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
            "/home/ahmed/prototype/.venv/lib/python3.9/site-packages/keras/src/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n",
            "2025-06-17 10:24:51.405051: W tensorflow/c/c_api.cc:305] Operation '{name:'dense_1_1/kernel/Assign' id:1028 op device:{requested: '', assigned: ''} def:{{{node dense_1_1/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_1_1/kernel, dense_1_1/kernel/Initializer/stateless_random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================================================================================\n",
            "Training iteration 0 at 2025-06-17 10:24:51.455015\n",
            "Autoencoder reconstruction error (infinity to 0): 0.717\n",
            "Counterfactual prediction gain (0 to 1): -0.104\n",
            "Sparsity (L1, infinity to 0): 0.767\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-17 10:24:51.532473: W tensorflow/c/c_api.cc:305] Operation '{name:'loss_2/mul' id:1096 op device:{requested: '', assigned: ''} def:{{{node loss_2/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_2/mul/x, loss_2/dense_1_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
            "2025-06-17 10:24:51.558038: W tensorflow/c/c_api.cc:305] Operation '{name:'training_1/Adam/dense_7/kernel/m/Assign' id:1565 op device:{requested: '', assigned: ''} def:{{{node training_1/Adam/dense_7/kernel/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_1/Adam/dense_7/kernel/m, training_1/Adam/dense_7/kernel/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
            "2025-06-17 10:24:52.106704: W tensorflow/c/c_api.cc:305] Operation '{name:'loss_3/AddN' id:1400 op device:{requested: '', assigned: ''} def:{{{node loss_3/AddN}} = AddN[N=3, T=DT_FLOAT, _has_manual_control_dependencies=true](loss_3/mul, loss_3/mul_1, model/activity_regularization/ActivityRegularizer/truediv)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
            "2025-06-17 10:24:52.138168: W tensorflow/c/c_api.cc:305] Operation '{name:'training_3/RMSprop/dense_2_1/kernel/rms/Assign' id:1898 op device:{requested: '', assigned: ''} def:{{{node training_3/RMSprop/dense_2_1/kernel/rms/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_3/RMSprop/dense_2_1/kernel/rms, training_3/RMSprop/dense_2_1/kernel/rms/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================================================================================\n",
            "Training iteration 1000 at 2025-06-17 10:26:09.658312\n",
            "Autoencoder reconstruction error (infinity to 0): 2.782\n",
            "Counterfactual prediction gain (0 to 1): 0.005\n",
            "Sparsity (L1, infinity to 0): 1.124\n",
            "========================================================================================\n",
            "Training iteration 1999 at 2025-06-17 10:27:27.355837\n",
            "Autoencoder reconstruction error (infinity to 0): 2.756\n",
            "Counterfactual prediction gain (0 to 1): 0.065\n",
            "Sparsity (L1, infinity to 0): 1.152\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics before immutable features projection:\n",
            "{'latency': '1.134 ± 0.023',\n",
            " 'latency_batch': '174.689',\n",
            " 'prediction_gain': '0.078 ± 0.014',\n",
            " 'reconstruction_error': '2.778 ± 0.010',\n",
            " 'sparsity': '9.267 ± 0.359'}\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics after immutable features projection:\n",
            "{'latency': '1.134 ± 0.023',\n",
            " 'latency_batch': '174.689',\n",
            " 'prediction_gain': '0.045 ± 0.013',\n",
            " 'reconstruction_error': '2.831 ± 0.086',\n",
            " 'sparsity': '6.028 ± 0.309'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ahmed/prototype/.venv/lib/python3.9/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "discriminator = create_discriminator()\n",
        "generator = create_generator(residuals=False)\n",
        "batches = infinite_data_stream(X_train, y_train, batch_size=256)\n",
        "\n",
        "method_name = \"regular_gan\"\n",
        "countergan = train_countergan(2, 4, 2000, classifier, discriminator, generator, batches)\n",
        "\n",
        "t_initial = time.time()\n",
        "counterfactuals = generator.predict(X_test)\n",
        "batch_latency = 1000*(time.time() - t_initial)\n",
        "\n",
        "latencies = np.zeros(len(X_test))\n",
        "for i, x in enumerate(X_test):\n",
        "    t_initial = time.time()\n",
        "    _ = generator.predict(np.expand_dims(x, axis=0))\n",
        "    latencies[i] = 1000*(time.time() - t_initial)\n",
        "\n",
        "print(\"-\"*80)\n",
        "print(\"Metrics before immutable features projection:\")\n",
        "pprint(compute_metrics(samples, counterfactuals, latencies, classifier, autoencoder,\n",
        "                    batch_latency=None))\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Set immutable features to original values\n",
        "counterfactuals[:, len(mutable_features):] = samples[:, len(mutable_features):]\n",
        "\n",
        "print(\"Metrics after immutable features projection:\")\n",
        "save_experiment(method_name, X_test, counterfactuals, latencies, batch_latency)\n",
        "\n",
        "generator.save(f\"{EXPERIMENT_PATH}/{method_name}/generator.h5\", save_format='h5')\n",
        "discriminator.save(f\"{EXPERIMENT_PATH}/{method_name}/discriminator.h5\", save_format='h5')\n",
        "countergan.save(f\"{EXPERIMENT_PATH}/{method_name}/countergan.h5\", save_format='h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7IvGXenSWL-"
      },
      "source": [
        "## CounteRGAN: first formulation for differentiable classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "mNQmxFS5SXIH",
        "outputId": "8ab0b191-abd2-44f3-ecd6-f980df21bd1c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-17 10:27:28.000746: W tensorflow/c/c_api.cc:305] Operation '{name:'dense_10/bias/Assign' id:2304 op device:{requested: '', assigned: ''} def:{{{node dense_10/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_10/bias, dense_10/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
            "2025-06-17 10:27:28.152273: W tensorflow/c/c_api.cc:305] Operation '{name:'loss_4/mul' id:2237 op device:{requested: '', assigned: ''} def:{{{node loss_4/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_4/mul/x, loss_4/dense_7_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
            "2025-06-17 10:27:28.193903: W tensorflow/c/c_api.cc:305] Operation '{name:'training_5/Adam/beta_2/Assign' id:2691 op device:{requested: '', assigned: ''} def:{{{node training_5/Adam/beta_2/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_5/Adam/beta_2, training_5/Adam/beta_2/Initializer/initial_value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================================================================================\n",
            "Training iteration 0 at 2025-06-17 10:27:28.070373\n",
            "Autoencoder reconstruction error (infinity to 0): 2.815\n",
            "Counterfactual prediction gain (0 to 1): -0.015\n",
            "Sparsity (L1, infinity to 0): 0.171\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-17 10:27:28.454723: W tensorflow/c/c_api.cc:305] Operation '{name:'loss_5/AddN' id:2543 op device:{requested: '', assigned: ''} def:{{{node loss_5/AddN}} = AddN[N=3, T=DT_FLOAT, _has_manual_control_dependencies=true](loss_5/mul, loss_5/mul_1, model_2/activity_regularization_1/ActivityRegularizer/truediv)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
            "2025-06-17 10:27:28.506582: W tensorflow/c/c_api.cc:305] Operation '{name:'training_7/RMSprop/rho/Assign' id:3044 op device:{requested: '', assigned: ''} def:{{{node training_7/RMSprop/rho/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_7/RMSprop/rho, training_7/RMSprop/rho/Initializer/initial_value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================================================================================\n",
            "Training iteration 1000 at 2025-06-17 10:28:48.318208\n",
            "Autoencoder reconstruction error (infinity to 0): 2.908\n",
            "Counterfactual prediction gain (0 to 1): 0.034\n",
            "Sparsity (L1, infinity to 0): 0.199\n",
            "========================================================================================\n",
            "Training iteration 1999 at 2025-06-17 10:30:07.966938\n",
            "Autoencoder reconstruction error (infinity to 0): 2.943\n",
            "Counterfactual prediction gain (0 to 1): 0.034\n",
            "Sparsity (L1, infinity to 0): 0.224\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics before immutable features projection:\n",
            "{'latency': '1.186 ± 0.031',\n",
            " 'latency_batch': '182.583',\n",
            " 'prediction_gain': '0.036 ± 0.007',\n",
            " 'reconstruction_error': '2.942 ± 0.178',\n",
            " 'sparsity': '1.800 ± 0.114'}\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics after immutable features projection:\n",
            "{'latency': '1.186 ± 0.031',\n",
            " 'latency_batch': '182.583',\n",
            " 'prediction_gain': '0.022 ± 0.005',\n",
            " 'reconstruction_error': '2.849 ± 0.173',\n",
            " 'sparsity': '1.129 ± 0.079'}\n"
          ]
        }
      ],
      "source": [
        "discriminator = create_discriminator()\n",
        "generator = create_generator(residuals=True)\n",
        "batches = infinite_data_stream(X_train, y_train, batch_size=256)\n",
        "\n",
        "method_name = \"countergan\"\n",
        "countergan = train_countergan(2, 4, 2000, classifier, discriminator, generator, batches)\n",
        "\n",
        "t_initial = time.time()\n",
        "counterfactuals = generator.predict(X_test)\n",
        "batch_latency = 1000*(time.time() - t_initial)\n",
        "\n",
        "latencies = np.zeros(len(X_test))\n",
        "for i, x in enumerate(X_test):\n",
        "    t_initial = time.time()\n",
        "    _ = generator.predict(np.expand_dims(x, axis=0))\n",
        "    latencies[i] = 1000*(time.time() - t_initial)\n",
        "\n",
        "print(\"-\"*80)\n",
        "print(\"Metrics before immutable features projection:\")\n",
        "pprint(compute_metrics(samples, counterfactuals, latencies, classifier, autoencoder,\n",
        "                    batch_latency=None))\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Set immutable features to original values\n",
        "counterfactuals[:, len(mutable_features):] = samples[:, len(mutable_features):]\n",
        "\n",
        "print(\"Metrics after immutable features projection:\")\n",
        "save_experiment(method_name, X_test, counterfactuals, latencies, batch_latency)\n",
        "\n",
        "generator.save(f\"{EXPERIMENT_PATH}/{method_name}/generator.h5\", save_format='h5')\n",
        "discriminator.save(f\"{EXPERIMENT_PATH}/{method_name}/discriminator.h5\", save_format='h5')\n",
        "countergan.save(f\"{EXPERIMENT_PATH}/{method_name}/countergan.h5\", save_format='h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pf5VJKqTBfd"
      },
      "source": [
        "## CounteRGAN: second formulation for any classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "LKjswCOCTC-4",
        "outputId": "036b03e9-76ac-4f42-ac37-e85f0bbf28a6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-17 10:30:08.677582: W tensorflow/c/c_api.cc:305] Operation '{name:'dense_12/bias/Assign' id:3292 op device:{requested: '', assigned: ''} def:{{{node dense_12/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_12/bias, dense_12/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================================================================================\n",
            "Training iteration 0 at 2025-06-17 10:30:08.768675\n",
            "Autoencoder reconstruction error (infinity to 0): 2.818\n",
            "Counterfactual prediction gain (0 to 1): 0.006\n",
            "Sparsity (L1, infinity to 0): 0.130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-17 10:30:08.924844: W tensorflow/c/c_api.cc:305] Operation '{name:'training_9/Adam/beta_2/Assign' id:3754 op device:{requested: '', assigned: ''} def:{{{node training_9/Adam/beta_2/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_9/Adam/beta_2, training_9/Adam/beta_2/Initializer/initial_value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
            "2025-06-17 10:30:09.229614: W tensorflow/c/c_api.cc:305] Operation '{name:'loss_7/AddN' id:3582 op device:{requested: '', assigned: ''} def:{{{node loss_7/AddN}} = AddN[N=2, T=DT_FLOAT, _has_manual_control_dependencies=true](loss_7/mul, model_4/activity_regularization_2/ActivityRegularizer/truediv)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
            "2025-06-17 10:30:09.293811: W tensorflow/c/c_api.cc:305] Operation '{name:'training_11/RMSprop/dense_15/bias/rms/Assign' id:4072 op device:{requested: '', assigned: ''} def:{{{node training_11/RMSprop/dense_15/bias/rms/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_11/RMSprop/dense_15/bias/rms, training_11/RMSprop/dense_15/bias/rms/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========================================================================================\n",
            "Training iteration 1000 at 2025-06-17 10:31:31.163693\n",
            "Autoencoder reconstruction error (infinity to 0): 2.867\n",
            "Counterfactual prediction gain (0 to 1): 0.012\n",
            "Sparsity (L1, infinity to 0): 0.189\n",
            "========================================================================================\n",
            "Training iteration 1999 at 2025-06-17 10:32:51.478993\n",
            "Autoencoder reconstruction error (infinity to 0): 2.964\n",
            "Counterfactual prediction gain (0 to 1): 0.018\n",
            "Sparsity (L1, infinity to 0): 0.232\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-17 10:32:51.555195: W tensorflow/c/c_api.cc:305] Operation '{name:'discriminator_2/dense_13/Sigmoid' id:3553 op device:{requested: '', assigned: ''} def:{{{node discriminator_2/dense_13/Sigmoid}} = Sigmoid[T=DT_FLOAT, _has_manual_control_dependencies=true](discriminator_2/dense_13/BiasAdd)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Metrics before immutable features projection:\n",
            "{'latency': '1.882 ± 0.993',\n",
            " 'latency_batch': '289.802',\n",
            " 'prediction_gain': '0.023 ± 0.004',\n",
            " 'reconstruction_error': '2.922 ± 0.186',\n",
            " 'sparsity': '1.651 ± 0.086'}\n",
            "--------------------------------------------------------------------------------\n",
            "Metrics after immutable features projection:\n",
            "{'latency': '1.882 ± 0.993',\n",
            " 'latency_batch': '289.802',\n",
            " 'prediction_gain': '0.013 ± 0.003',\n",
            " 'reconstruction_error': '2.872 ± 0.184',\n",
            " 'sparsity': '1.006 ± 0.068'}\n"
          ]
        }
      ],
      "source": [
        "discriminator = create_discriminator()\n",
        "generator = create_generator(residuals=True)\n",
        "batches = infinite_data_stream(X_train, y_train, batch_size=256)\n",
        "\n",
        "method_name = \"countergan-wt\"\n",
        "countergan = train_countergan(2, 3, 2000, classifier, discriminator, generator, \n",
        "                              batches, weighted_version=True)\n",
        "\n",
        "t_initial = time.time()\n",
        "counterfactuals = generator.predict(X_test)\n",
        "batch_latency = 1000*(time.time() - t_initial)\n",
        "\n",
        "latencies = np.zeros(len(X_test))\n",
        "for i, x in enumerate(X_test):\n",
        "    t_initial = time.time()\n",
        "    _ = countergan.predict(np.expand_dims(x, axis=0))\n",
        "    latencies[i] = 1000*(time.time() - t_initial)\n",
        "\n",
        "print(\"-\"*80)\n",
        "print(\"Metrics before immutable features projection:\")\n",
        "pprint(compute_metrics(samples, counterfactuals, latencies, classifier, autoencoder,\n",
        "                    batch_latency=None))\n",
        "print(\"-\"*80)\n",
        "\n",
        "# Set immutable features to original values\n",
        "counterfactuals[:, len(mutable_features):] = samples[:, len(mutable_features):]\n",
        "\n",
        "print(\"Metrics after immutable features projection:\")\n",
        "save_experiment(method_name, X_test, counterfactuals, latencies, batch_latency)\n",
        "\n",
        "generator.save(f\"{EXPERIMENT_PATH}/{method_name}/generator.h5\", save_format='h5')\n",
        "discriminator.save(f\"{EXPERIMENT_PATH}/{method_name}/discriminator.h5\", save_format='h5')\n",
        "countergan.save(f\"{EXPERIMENT_PATH}/{method_name}/countergan.h5\", save_format='h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T-D0Jj0LVJM"
      },
      "source": [
        "## Generate the benchmark table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "5w-2mCNALc8O",
        "outputId": "5adf7fa7-ef41-43d5-df19-c6f1eabfabf2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "RGD",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "CSGP",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "GAN",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "CounterGAN",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "CounterRGAN-wt",
                  "rawType": "object",
                  "type": "string"
                }
              ],
              "ref": "733ce52c-8f4e-457a-a52c-c508576556e6",
              "rows": [
                [
                  "↓ Realism",
                  "2.817 ± 0.168",
                  "2.738 ± 0.166",
                  "2.831 ± 0.086",
                  "2.849 ± 0.173",
                  "2.872 ± 0.184"
                ],
                [
                  "↑ Prediction gain",
                  "0.021 ± 0.002",
                  "0.005 ± 0.003",
                  "0.045 ± 0.013",
                  "0.022 ± 0.005",
                  "0.013 ± 0.003"
                ],
                [
                  "↓ Sparsity",
                  "0.567 ± 0.042",
                  "0.092 ± 0.046",
                  "6.028 ± 0.309",
                  "1.129 ± 0.079",
                  "1.006 ± 0.068"
                ],
                [
                  "↓ Latency (ms)",
                  "1770.123 ± 30.214",
                  "8741.106 ± 76.150",
                  "1.134 ± 0.023",
                  "1.186 ± 0.031",
                  "1.882 ± 0.993"
                ],
                [
                  "↓ Batch latency (ms)",
                  "272598.989",
                  "1346130.346",
                  "174.689",
                  "182.583",
                  "289.802"
                ]
              ],
              "shape": {
                "columns": 5,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RGD</th>\n",
              "      <th>CSGP</th>\n",
              "      <th>GAN</th>\n",
              "      <th>CounterGAN</th>\n",
              "      <th>CounterRGAN-wt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>↓ Realism</th>\n",
              "      <td>2.817 ± 0.168</td>\n",
              "      <td>2.738 ± 0.166</td>\n",
              "      <td>2.831 ± 0.086</td>\n",
              "      <td>2.849 ± 0.173</td>\n",
              "      <td>2.872 ± 0.184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>↑ Prediction gain</th>\n",
              "      <td>0.021 ± 0.002</td>\n",
              "      <td>0.005 ± 0.003</td>\n",
              "      <td>0.045 ± 0.013</td>\n",
              "      <td>0.022 ± 0.005</td>\n",
              "      <td>0.013 ± 0.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>↓ Sparsity</th>\n",
              "      <td>0.567 ± 0.042</td>\n",
              "      <td>0.092 ± 0.046</td>\n",
              "      <td>6.028 ± 0.309</td>\n",
              "      <td>1.129 ± 0.079</td>\n",
              "      <td>1.006 ± 0.068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>↓ Latency (ms)</th>\n",
              "      <td>1770.123 ± 30.214</td>\n",
              "      <td>8741.106 ± 76.150</td>\n",
              "      <td>1.134 ± 0.023</td>\n",
              "      <td>1.186 ± 0.031</td>\n",
              "      <td>1.882 ± 0.993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>↓ Batch latency (ms)</th>\n",
              "      <td>272598.989</td>\n",
              "      <td>1346130.346</td>\n",
              "      <td>174.689</td>\n",
              "      <td>182.583</td>\n",
              "      <td>289.802</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    RGD               CSGP            GAN  \\\n",
              "↓ Realism                 2.817 ± 0.168      2.738 ± 0.166  2.831 ± 0.086   \n",
              "↑ Prediction gain         0.021 ± 0.002      0.005 ± 0.003  0.045 ± 0.013   \n",
              "↓ Sparsity                0.567 ± 0.042      0.092 ± 0.046  6.028 ± 0.309   \n",
              "↓ Latency (ms)        1770.123 ± 30.214  8741.106 ± 76.150  1.134 ± 0.023   \n",
              "↓ Batch latency (ms)         272598.989        1346130.346        174.689   \n",
              "\n",
              "                         CounterGAN CounterRGAN-wt  \n",
              "↓ Realism             2.849 ± 0.173  2.872 ± 0.184  \n",
              "↑ Prediction gain     0.022 ± 0.005  0.013 ± 0.003  \n",
              "↓ Sparsity            1.129 ± 0.079  1.006 ± 0.068  \n",
              "↓ Latency (ms)        1.186 ± 0.031  1.882 ± 0.993  \n",
              "↓ Batch latency (ms)        182.583        289.802  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "METHODS = [\"rgd\", \"csgp\", \"regular_gan\", \"countergan\", \"countergan-wt\"]\n",
        "METRIC_NAMES = [\n",
        "    \"prediction_gain\", \"reconstruction_error\", \"sparsity\", \"latency\", \"latency_batch\"\n",
        "]\n",
        "\n",
        "metrics = dict()\n",
        "for method in METHODS:\n",
        "    method_metrics = json.load(open(f\"{EXPERIMENT_PATH}/{method}/metrics.json\", \"r\"))\n",
        "    method_metrics = {k: v for k, v in method_metrics.items() if k in METRIC_NAMES}\n",
        "    metrics[method] = method_metrics\n",
        "\n",
        "metrics = pd.DataFrame(metrics)\n",
        "metrics.columns =  [\"RGD\",  \"CSGP\", \"GAN\", \"CounterGAN\", \"CounterRGAN-wt\"] \n",
        "\n",
        "metrics.index = [\n",
        "    \"↓ Realism\",\n",
        "    \"↑ Prediction gain\",\n",
        "    \"↓ Sparsity\",\n",
        "    \"↓ Latency (ms)\",\n",
        "    \"↓ Batch latency (ms)\",\n",
        "]\n",
        "\n",
        "metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKAfN55k9zjd"
      },
      "source": [
        "## Individual examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "s69m-GMnXxNf",
        "outputId": "facf23e6-0098-4842-b783-d5cc91218964"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Insulin",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Glucose",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "SkinThickness",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "BMI",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "BloodPressure",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Age",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "DiabetesPedigreeFunction",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Pregnancies",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "ref": "135ee949-edcc-475c-8055-c26f9790a6e8",
              "rows": [
                [
                  "0",
                  "66.0",
                  "84.0",
                  "22.0",
                  "35.8",
                  "64.0",
                  "21.0",
                  "0.545",
                  "4.440892098500626e-16"
                ],
                [
                  "1",
                  "125.0",
                  "84.0",
                  "31.0",
                  "38.2",
                  "82.0",
                  "23.0",
                  "0.233",
                  "4.440892098500626e-16"
                ],
                [
                  "2",
                  "0.0",
                  "122.0",
                  "27.0",
                  "36.8",
                  "70.0",
                  "27.0",
                  "0.34",
                  "1.9999999999999998"
                ],
                [
                  "3",
                  "22.0",
                  "126.0",
                  "27.0",
                  "29.6",
                  "78.0",
                  "40.0",
                  "0.439",
                  "5.0"
                ],
                [
                  "4",
                  "0.0",
                  "97.0",
                  "40.0",
                  "38.1",
                  "70.0",
                  "30.0",
                  "0.21799999999999997",
                  "1.0"
                ]
              ],
              "shape": {
                "columns": 8,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Insulin</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>BMI</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>Age</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Pregnancies</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>66.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>35.8</td>\n",
              "      <td>64.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.545</td>\n",
              "      <td>4.440892e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>38.2</td>\n",
              "      <td>82.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.233</td>\n",
              "      <td>4.440892e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>70.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.340</td>\n",
              "      <td>2.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>22.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>29.6</td>\n",
              "      <td>78.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.439</td>\n",
              "      <td>5.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>38.1</td>\n",
              "      <td>70.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.218</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Insulin  Glucose  SkinThickness   BMI  BloodPressure   Age  \\\n",
              "0     66.0     84.0           22.0  35.8           64.0  21.0   \n",
              "1    125.0     84.0           31.0  38.2           82.0  23.0   \n",
              "2      0.0    122.0           27.0  36.8           70.0  27.0   \n",
              "3     22.0    126.0           27.0  29.6           78.0  40.0   \n",
              "4      0.0     97.0           40.0  38.1           70.0  30.0   \n",
              "\n",
              "   DiabetesPedigreeFunction   Pregnancies  \n",
              "0                     0.545  4.440892e-16  \n",
              "1                     0.233  4.440892e-16  \n",
              "2                     0.340  2.000000e+00  \n",
              "3                     0.439  5.000000e+00  \n",
              "4                     0.218  1.000000e+00  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "negative_idx = np.where(classifier.predict(X_test)[:, 1] < 0.5)[0]\n",
        "x_negative = X_test[negative_idx]\n",
        "original_features = standard_scaler.inverse_transform(x_negative)\n",
        "negative_df = pd.DataFrame(original_features, columns=features)\n",
        "negative_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "Ud0Dwe0GZXFT",
        "outputId": "5c247d8b-e9a7-42e2-95d0-35492781d306"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Insulin",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Glucose",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "SkinThickness",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "BMI",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "BloodPressure",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Age",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "DiabetesPedigreeFunction",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Pregnancies",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "ref": "2fb1eae2-e16d-4d35-9756-94da7a6e7c69",
              "rows": [
                [
                  "0",
                  "12.927764892578125",
                  "-0.00337982177734375",
                  "7.759355545043945",
                  "1.7352745056152372",
                  "1.9029541015625",
                  "0.0",
                  "0.0",
                  "0.0"
                ],
                [
                  "1",
                  "20.727264404296875",
                  "6.607536315917969",
                  "1.8210525512695312",
                  "3.730339813232419",
                  "-6.1799774169921875",
                  "0.0",
                  "0.0",
                  "0.0"
                ],
                [
                  "2",
                  "-14.777436256408691",
                  "3.26019287109375",
                  "-1.961944580078125",
                  "-2.154393005371091",
                  "4.6557464599609375",
                  "0.0",
                  "0.0",
                  "0.0"
                ],
                [
                  "3",
                  "-7.547711372375488",
                  "-1.1837234497070312",
                  "-2.4943389892578125",
                  "0.6958202362060533",
                  "-0.6272659301757812",
                  "0.0",
                  "0.0",
                  "0.0"
                ],
                [
                  "4",
                  "-26.555557250976562",
                  "-5.3602752685546875",
                  "-3.1975135803222656",
                  "-0.6065078735351577",
                  "2.0132827758789062",
                  "0.0",
                  "0.0",
                  "0.0"
                ]
              ],
              "shape": {
                "columns": 8,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Insulin</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>BMI</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>Age</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Pregnancies</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12.927765</td>\n",
              "      <td>-0.003380</td>\n",
              "      <td>7.759356</td>\n",
              "      <td>1.735275</td>\n",
              "      <td>1.902954</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.727264</td>\n",
              "      <td>6.607536</td>\n",
              "      <td>1.821053</td>\n",
              "      <td>3.730340</td>\n",
              "      <td>-6.179977</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-14.777436</td>\n",
              "      <td>3.260193</td>\n",
              "      <td>-1.961945</td>\n",
              "      <td>-2.154393</td>\n",
              "      <td>4.655746</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-7.547711</td>\n",
              "      <td>-1.183723</td>\n",
              "      <td>-2.494339</td>\n",
              "      <td>0.695820</td>\n",
              "      <td>-0.627266</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-26.555557</td>\n",
              "      <td>-5.360275</td>\n",
              "      <td>-3.197514</td>\n",
              "      <td>-0.606508</td>\n",
              "      <td>2.013283</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Insulin   Glucose  SkinThickness       BMI  BloodPressure  Age  \\\n",
              "0  12.927765 -0.003380       7.759356  1.735275       1.902954  0.0   \n",
              "1  20.727264  6.607536       1.821053  3.730340      -6.179977  0.0   \n",
              "2 -14.777436  3.260193      -1.961945 -2.154393       4.655746  0.0   \n",
              "3  -7.547711 -1.183723      -2.494339  0.695820      -0.627266  0.0   \n",
              "4 -26.555557 -5.360275      -3.197514 -0.606508       2.013283  0.0   \n",
              "\n",
              "   DiabetesPedigreeFunction  Pregnancies  \n",
              "0                       0.0          0.0  \n",
              "1                       0.0          0.0  \n",
              "2                       0.0          0.0  \n",
              "3                       0.0          0.0  \n",
              "4                       0.0          0.0  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "counterfactuals = standard_scaler.inverse_transform(\n",
        "    generator.predict(X_test[negative_idx])\n",
        ")\n",
        "residuals = (counterfactuals - \n",
        "             standard_scaler.inverse_transform(X_test[negative_idx]))\n",
        "residuals_df = pd.DataFrame(residuals, columns=features)\n",
        "residuals_df[list(immutable_features)] = 0.\n",
        "residuals_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "qW9zy0bTYM5h",
        "outputId": "e74d92aa-3aa2-4d08-80d6-7a836c7b86c5"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[21], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m method_outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGD\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m d\n\u001b[1;32m     24\u001b[0m explanation \u001b[38;5;241m=\u001b[39m cf_proto\u001b[38;5;241m.\u001b[39mexplain(sample, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, k_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, target_class\u001b[38;5;241m=\u001b[39m[DESIRED_CLASS])\n\u001b[0;32m---> 25\u001b[0m counterfactual \u001b[38;5;241m=\u001b[39m \u001b[43mexplanation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     26\u001b[0m scaled_counterfactual \u001b[38;5;241m=\u001b[39m compute_residuals(sample, counterfactual)\n\u001b[1;32m     27\u001b[0m d \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(features, \u001b[38;5;28mlist\u001b[39m(scaled_counterfactual))}\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "sample_idx = 20\n",
        "sample = np.expand_dims(X_test[sample_idx], axis=0)\n",
        "\n",
        "def compute_residuals(sample, counterfactual):\n",
        "    counterfactual = standard_scaler.inverse_transform(counterfactual)\n",
        "    residuals = (counterfactual - standard_scaler.inverse_transform(sample))[0]\n",
        "    residuals[-len(immutable_features):] = 0\n",
        "    return residuals\n",
        "\n",
        "method_outputs = dict()\n",
        "\n",
        "d = negative_df.iloc[sample_idx].to_dict()\n",
        "d[\"Classifier Prediction\"] = classifier.predict(sample)[0][1]\n",
        "method_outputs[\"Initial values\"] = d\n",
        "\n",
        "\n",
        "explanation = cf.explain(sample)\n",
        "counterfactual = explanation.cf['X']\n",
        "scaled_counterfactual = compute_residuals(sample, counterfactual)\n",
        "d = {k: v for k, v in zip(features, list(scaled_counterfactual))}\n",
        "d[\"Classifier Prediction\"] = classifier.predict(counterfactual)[0][1]\n",
        "method_outputs[\"RGD\"] = d\n",
        "\n",
        "explanation = cf_proto.explain(sample, k=5, k_type='mean', target_class=[DESIRED_CLASS])\n",
        "counterfactual = explanation.cf['X']\n",
        "scaled_counterfactual = compute_residuals(sample, counterfactual)\n",
        "d = {k: v for k, v in zip(features, list(scaled_counterfactual))}\n",
        "d[\"Classifier Prediction\"] = classifier.predict(counterfactual)[0][1]\n",
        "method_outputs[\"CSGP\"] = d\n",
        "\n",
        "for method in [\"regular_gan\", \"countergan\", \"countergan-wt\"]:\n",
        "    generator = load_model(f\"{EXPERIMENT_PATH}/{method}/generator.h5\")\n",
        "    counterfactual = generator.predict(sample)\n",
        "    scaled_counterfactual = compute_residuals(sample, counterfactual)\n",
        "    d = {k: v for k, v in zip(features, list(scaled_counterfactual))}\n",
        "    d[\"Classifier Prediction\"] = classifier.predict(counterfactual)[0][1]\n",
        "    method_outputs[method] = d\n",
        "\n",
        "df = pd.DataFrame(method_outputs)\n",
        "df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "kdd_counterfactuals_diabetes.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.22"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
